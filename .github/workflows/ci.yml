name: CI

on:
  push:
    branches: [ master, main ]
    tags:
      - 'v*'
  pull_request:
    branches: [ master, main ]
  workflow_dispatch:

jobs:
  test:
    name: Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest

    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12', '3.13']

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true

      - name: Install dependencies
        run: |
          uv sync --all-groups

      - name: Run pytest
        run: |
          uv run pytest -v --cov=chaosbench --cov-report=term-missing

      - name: Validate dataset statistics
        run: |
          uv run python -c "
          import json
          from pathlib import Path
          total = 0
          for f in sorted(Path('data').glob('v22_*.jsonl')):
              count = sum(1 for line in open(f) if line.strip())
              total += count
              print(f'  {f.name}: {count}')
          print(f'Total v2.2 questions: {total}')
          assert total == 21037, f'Expected 21037, got {total}'
          "

  lint:
    name: Code Quality
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Check file naming conventions
        run: |
          # Ensure README.md exists (not Readme.md)
          if [ ! -f "README.md" ]; then
            echo "Error: README.md not found (should be uppercase)"
            exit 1
          fi
          echo "[OK] README.md found"

      - name: Check for placeholder URLs
        run: |
          # Check for placeholder URLs in key files
          if grep -r "yourusername" --include="*.md" --include="*.toml" --include="*.cff" .; then
            echo "Error: Found placeholder URLs (yourusername)"
            exit 1
          fi
          echo "[OK] No placeholder URLs found"

      - name: Verify license files exist
        run: |
          if [ ! -f "LICENSE" ]; then
            echo "Error: LICENSE file not found"
            exit 1
          fi
          if [ ! -f "LICENSE_DATA" ]; then
            echo "Error: LICENSE_DATA file not found"
            exit 1
          fi
          echo "[OK] License files found"

  dataset-integrity:
    name: Dataset Integrity
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Check v2.2 canonical dataset files exist
        run: |
          for family in adversarial atomic consistency_paraphrase cross_indicator extended_systems fol_inference indicator_diagnostics multi_hop perturbation_robustness regime_transition; do
            if [ ! -f "data/v22_${family}.jsonl" ]; then
              echo "Error: data/v22_${family}.jsonl not found"
              exit 1
            fi
          done
          echo "[OK] All 10 v2.2 canonical files found"

      - name: Validate JSON format
        run: |
          python << 'VALIDATE_JSON_EOF'
          import json
          import sys
          from pathlib import Path

          v22_files = sorted(Path('data').glob('v22_*.jsonl'))
          assert len(v22_files) == 10, f"Expected 10 v22_*.jsonl files, found {len(v22_files)}"

          errors = []
          for batch_file in v22_files:
              try:
                  with open(batch_file) as f:
                      for line_num, line in enumerate(f, 1):
                          if line.strip():
                              json.loads(line)
              except json.JSONDecodeError as e:
                  errors.append(f'{batch_file}:{line_num}: {e}')
              except Exception as e:
                  errors.append(f'{batch_file}: {e}')

          if errors:
              print('JSON validation errors:')
              for error in errors:
                  print(f'  {error}')
              sys.exit(1)
          else:
              print('[OK] All v2.2 JSONL files are valid')
          VALIDATE_JSON_EOF

      - name: Check systems directory
        run: |
          system_count=$(ls -1 systems/*.json 2>/dev/null | grep -v dysts | wc -l)
          if [ "$system_count" -lt 25 ] || [ "$system_count" -gt 35 ]; then
            echo "Error: Expected ~30 core system files, found $system_count"
            exit 1
          fi
          echo "[OK] Found $system_count core system definition files"

          if [ -d "systems/dysts" ]; then
            dysts_count=$(ls -1 systems/dysts/*.json 2>/dev/null | wc -l)
            echo "[OK] Found $dysts_count dysts system files"
          fi

      - name: Validate system JSON files
        run: |
          python << 'VALIDATE_SYSTEMS_EOF'
          import json
          import sys
          from pathlib import Path

          systems_dir = Path('systems')
          errors = []

          for system_file in systems_dir.glob('*.json'):
              try:
                  with open(system_file) as f:
                      system_data = json.load(f)
                  # Verify required fields
                  if 'system_id' not in system_data:
                      errors.append(f'{system_file}: Missing system_id field')
                  if 'truth_assignment' not in system_data:
                      errors.append(f'{system_file}: Missing truth_assignment field')
              except json.JSONDecodeError as e:
                  errors.append(f'{system_file}: JSON decode error - {e}')
              except Exception as e:
                  errors.append(f'{system_file}: {e}')

          if errors:
              print('System JSON validation errors:')
              for error in errors:
                  print(f'  {error}')
              sys.exit(1)
          else:
              print('[OK] All system JSON files are valid')
          VALIDATE_SYSTEMS_EOF

      - name: Validate manifest integrity
        run: |
          python << 'VALIDATE_MANIFEST_EOF'
          import json
          import sys
          from pathlib import Path

          manifest_path = Path('data/v2_manifest.json')
          if not manifest_path.exists():
              print('Warning: v2_manifest.json not found')
              sys.exit(0)

          manifest = json.load(open(manifest_path))
          assert manifest.get('version') == '2.2.0', f"Expected version 2.2.0, got {manifest.get('version')}"

          batches = manifest.get('batches', {})
          for name, info in batches.items():
              fpath = Path(f'data/{name}.jsonl')
              if fpath.exists():
                  actual = sum(1 for line in open(fpath) if line.strip())
                  expected = info['count']
                  assert actual == expected, f"{name}: manifest says {expected}, file has {actual}"

          print('[OK] Manifest integrity verified')
          VALIDATE_MANIFEST_EOF

  validate-v2-dataset:
    name: Validate v2 Dataset
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true

      - name: Install dependencies
        run: |
          uv sync --all-groups

      - name: Run v2 dataset validation
        run: |
          uv run python scripts/validate_v2.py --strict --max-duplicate-questions 200 --skip-tests

      - name: Run dataset axis analysis
        run: |
          uv run python scripts/analyze_dataset_axes.py

      - name: Run sanity checks
        run: |
          uv run python scripts/sanity_checks.py

  smoke-build-check:
    name: Smoke Build Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true

      - name: Install dependencies
        run: |
          uv sync --all-groups

      - name: Run build dry-run smoke test
        run: |
          # Validate CI smoke config exists and parses
          if [ ! -f configs/generation/ci_smoke.yaml ]; then
            echo "Error: configs/generation/ci_smoke.yaml not found"
            exit 1
          fi
          uv run python -c "import yaml; yaml.safe_load(open('configs/generation/ci_smoke.yaml'))"
          echo "[OK] CI smoke config file parses successfully"

  release-gates:
    name: Release Gates
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v') || github.event_name == 'workflow_dispatch'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true

      - name: Install dependencies
        run: |
          uv sync --all-groups

      - name: Run strict release validation
        run: |
          mkdir -p artifacts
          uv run python scripts/validate_v2.py --strict --max-duplicate-questions 200 --skip-tests | tee artifacts/validate_v2.log

      - name: Generate run manifest smoke artifact
        run: |
          uv run python run_benchmark.py --model dummy --mode zeroshot --workers 1 --max-items 10 --out-dir results_ci --clear-checkpoints | tee artifacts/run_benchmark_dummy.log
          mkdir -p artifacts/run_manifests
          if ls runs/manifest_*.json 1> /dev/null 2>&1; then cp runs/manifest_*.json artifacts/run_manifests/; fi
          if [ -f results_ci/dummy_zeroshot/run_manifest.json ]; then cp results_ci/dummy_zeroshot/run_manifest.json artifacts/run_manifests/; fi

      - name: Collect release smoke proof bundle
        run: |
          mkdir -p artifacts/release_smoke
          test -f results_ci/dummy_zeroshot/summary.json
          test -f results_ci/dummy_zeroshot/run_meta.json
          cp results_ci/dummy_zeroshot/summary.json artifacts/release_smoke/
          cp results_ci/dummy_zeroshot/run_meta.json artifacts/release_smoke/
          if [ -f results_ci/dummy_zeroshot/metrics_overview.csv ]; then cp results_ci/dummy_zeroshot/metrics_overview.csv artifacts/release_smoke/; fi

      - name: Upload release gate artifacts
        uses: actions/upload-artifact@v4
        with:
          name: release-gate-artifacts
          path: artifacts/
          if-no-files-found: error
